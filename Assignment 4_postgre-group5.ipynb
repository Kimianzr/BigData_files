{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section A: Getting Data by kaggle API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.1 First we need to add our kaggle.jason file (extracted from kaggle account) to our computer directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \n",
    "#!mkdir ~/.kaggle\n",
    "#!mv kaggle.json ~/.kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2 Reviewing Covid related dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "!kaggle datasets list -s \"Covid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.dataset_download_files('imdevskp/corona-virus-report',unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Covid_set_name=\"C:/Users/TUF/OneDrive - University of New Brunswick/Desktop/desctop-2023/big data/تکلیف4/country_wise_latest.csv\"\n",
    "data=pd.read_csv(Covid_set_name)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Section B: Fixing data Columns for PostgreSQL queries synatx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.1 Replacing signs  ( `~!@#$%^&*)(-+=,.?/\\|  ) with underscore (_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modfied_columns={}\n",
    "for column_I in data.columns:\n",
    "    new_column=column_I\n",
    "    for operations in \" `~!@#$%^&*)(-+=,.?/\\|\":\n",
    "        new_column=new_column.replace(operations, \"_\")\n",
    "    modfied_columns[column_I]=new_column\n",
    "data.rename(columns = modfied_columns,inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.2 Adding Underscore (_) before number starting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modfied_columns2={}\n",
    "for column_I in data.columns:\n",
    "    first_char=column_I[0]\n",
    "    if first_char in \"0123456789\":\n",
    "        first_char= \"_\" + first_char\n",
    "        new_column=first_char + column_I[1:]     \n",
    "        modfied_columns2[column_I]=new_column\n",
    "data.rename(columns = modfied_columns2,inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.3 outputing processed dataset for copying into PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('C:/Program Files/PostgreSQL/15/sqldata.csv',index=False)\n",
    "sql_data=pd.read_csv('sqldata.csv')\n",
    "sql_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SectionC: Copying data into PosgreSQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C1. Building automatic query for : Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_table_query(data,Table_name,PK_index=0):\n",
    "    Ptype_adjustment={\"<class 'str'>\":\"varchar\" ,\n",
    "                  \"<class 'numpy.int64'>\":\"int\",\"<class 'int'>\":\"int\",\n",
    "                  \"<class 'numpy.float64'>\":\"float(24)\",\"<class 'float'>\":\"float(24)\" }\n",
    "\n",
    "    query=f'Create Table {Table_name} ({data.columns[PK_index]} {Ptype_adjustment[str(type(data.iloc[0,PK_index]))]} PRIMARY KEY,'\n",
    "    for index,value in enumerate(data.columns):\n",
    "        if index != PK_index:\n",
    "            query=f'{query} {data.columns[index]} {Ptype_adjustment[str(type(data.iloc[0,index]))]},'\n",
    "\n",
    "\n",
    "    new_query = list(query)\n",
    "    new_query[-1] = ')'\n",
    "    new_query=''.join(new_query)\n",
    "    new_query=new_query +\";\"\n",
    "    new_query\n",
    "    return new_query\n",
    "\n",
    "Create_table_query(data,\"covid_set\",0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C2. Building automatic query for : Copy table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Copy_Query(Path,Table_name):\n",
    "    dataset=pd.read_csv(Path)\n",
    "    headings=','.join(list(dataset.columns))\n",
    "    newquery2= \"COPY \"+ Table_name+\"(\" + headings +\") From \" + \"'\" +Path + \"'\" + \"DELIMITER ','\" + \"CSV HEADER;\"\n",
    "    return newquery2\n",
    "Create_Copy_Query('C:/Program Files/PostgreSQL/15/sqldata.csv',\"Covid_set\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.3 Copying data into PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Copy_to_SQL(Path,Table_name,PK_index=0):\n",
    "    #Initialization\n",
    "    conn = psycopg2.connect(database=\"GGE6505_AS04\",user='postgres',\n",
    "                            password=\"12345\",host=\"localhost\", port='5432')\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor()\n",
    "    # reading data into dataframe\n",
    "    dataset=pd.read_csv(Path)\n",
    "    # creating table\n",
    "    SQL_Create_table = Create_table_query(data,Table_name,PK_index)\n",
    "    cursor.execute(SQL_Create_table)\n",
    "    # Copy table\n",
    "    SQL_Copy_table = Create_Copy_Query(Path,Table_name)\n",
    "    cursor.execute(SQL_Copy_table)\n",
    "    #Finalization\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "Copy_to_SQL(Path='C:/Program Files/PostgreSQL/15/sqldata.csv',\n",
    "            Table_name=\"mytbl\",\n",
    "            PK_index=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.4 Query_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Execute_Query(SQL):\n",
    "    #Initialization\n",
    "    conn = psycopg2.connect(database=\"GGE6505_AS04\",user='postgres',\n",
    "                            password=\"12345\",host=\"localhost\", port='5432')\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(SQL)\n",
    "    colnames = [desc[0] for desc in cursor.description]\n",
    "    df=pd.DataFrame(columns= colnames)\n",
    "    for i in cursor.fetchall():\n",
    "        to_append = list(i)\n",
    "        df_length = len(df)\n",
    "        df.loc[df_length] = to_append\n",
    "          \n",
    "    #Finalization\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL1=\"Select country_region,deaths,Confirmed,who_region From mytbl ORDER BY deaths DESC LIMIT 4\"\n",
    "df_sql1=Execute_Query(SQL1)\n",
    "df_sql1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL2=\"Select SUM(deaths),who_region From mytbl GROUP BY who_region\"\n",
    "df_sql2=Execute_Query(SQL2)\n",
    "plt.pie(df_sql2[\"sum\"],  labels= df_sql2[\"who_region\"])\n",
    "plt.title(\" deaths in regions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
